{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Concatenate\n",
    "from IPython import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import imageio\n",
    "from compas.datastructures import Mesh\n",
    "from compas_plotters.meshplotter import MeshPlotter\n",
    "import networkx \n",
    "from networkx.algorithms.components.connected import connected_components\n",
    "from keras import layers, activations\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_directory=os.getcwd()\n",
    "data= os.path.join(job_directory, \"Data\",\"dense_meshquarter.obj\")\n",
    "meshdense = Mesh.from_obj(data)\n",
    "Trainning_Dataset_dir= os.path.join(job_directory, \"Trainning_Dataset\")\n",
    "feautures_flatten_dir=os.path.join(Trainning_Dataset_dir, \"feautures_flatten.npy\")\n",
    "feautures=np.load(feautures_flatten_dir, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mesh from an adjacency matrix\n",
    "def Mesh_from_mtx(mtx):\n",
    "    vertices_old = list(meshdense.vertices())\n",
    "    v_old=[]\n",
    "    for i in vertices_old:\n",
    "        i_coordinates_old=Mesh.vertex_coordinates(meshdense, i, axes='xyz')\n",
    "        v_old.append(i_coordinates_old)\n",
    "\n",
    "    #get the connected edges\n",
    "    D=networkx.DiGraph(mtx) \n",
    "    edges = [[u, v] for [u, v] in D.edges()]\n",
    "\n",
    "    #sort the tuples of edges\n",
    "    temp=[]\n",
    "    for i in edges:\n",
    "        temp.append(tuple(sorted(i)))\n",
    "\n",
    "    #delete duplicate edges\n",
    "    temp=set(temp) #first create ser\n",
    "\n",
    "    temp=tuple(temp) #convert set to tuple\n",
    "\n",
    "    #Convert to list\n",
    "    edges=[]\n",
    "    for i in temp:\n",
    "        z=[]\n",
    "        for y in i:\n",
    "            z.append(v_old[y])\n",
    "        edges.append(z)\n",
    "\n",
    "    mrebuild=Mesh.from_lines(edges)\n",
    "    return (mrebuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_to_matrix(flatten_lst,shape1):\n",
    "    array_zero=np.zeros((shape1,shape1))\n",
    "    y=0\n",
    "    for i in range(shape1):\n",
    "        for e in range(i):\n",
    "            array_zero[i,e]=flatten_lst[y]\n",
    "            array_zero[e,i]=flatten_lst[y]\n",
    "            y=y+1\n",
    "    array_new=array_zero\n",
    "    return array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the Generation Exists\n",
    "def exist(mtx,feautures_flatten):\n",
    "    ex=0\n",
    "    for i in range(feautures_flatten.shape[0]):\n",
    "        A=feautures_flatten[i]\n",
    "        B=mtx    \n",
    "        C=(A==B).all()\n",
    "        if C==1:\n",
    "            ex=ex+C\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            #reconstruction =tf.round(self.decoder(z))\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.mean_squared_error(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 3240\n",
    "           \n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var) \n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5 \n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "      if isinstance(data, tuple):\n",
    "        data = data[0]\n",
    "\n",
    "      z_mean, z_log_var, z = self.encoder(data)\n",
    "      reconstruction = self.decoder(z)\n",
    "      reconstruction_loss = tf.reduce_mean(\n",
    "            keras.losses.mean_squared_error(data, reconstruction)\n",
    "      )\n",
    "      reconstruction_loss *= 81 * 81\n",
    "\n",
    "      kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "      kl_loss = tf.reduce_mean(kl_loss)\n",
    "      kl_loss *= -0.5\n",
    "      total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "      return {\n",
    "          \"loss\": total_loss,\n",
    "          \"reconstruction_loss\": reconstruction_loss,\n",
    "          \"kl_loss\": kl_loss,\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_directory=os.getcwd()\n",
    "location= os.path.join(job_directory, \"Saved_VAE/\")\n",
    "encoder= keras.models.load_model(location + \"encoder_arch\") #Loading the encoder model\n",
    "decoder= keras.models.load_model(location +\"decoder_arch\") #Loading the decoder model\n",
    "vae = VAE(encoder, decoder) #You need to have VAE class defined for this to works\n",
    "vae.get_layer('encoder').load_weights(location + \"encoder_weights.h5\") #On a given encoder model defined by vae_new we want to load the weights\n",
    "vae.get_layer('decoder').load_weights(location +\"decoder_weights.h5\") #for encoder and decoder\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_s= os.path.join(job_directory, \"Surrogate/\")\n",
    "surrogate= keras.models.load_model(location_s) #Loading the surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a case\n",
    "load_case_dir= os.path.join(job_directory, \"Cases\",\"int_665\",\"int_665_lr2.5.npy\")\n",
    "z_ar=np.load(load_case_dir, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "z=tf.convert_to_tensor(z_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the sample performance is: 0.16579011 int: 999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gradient descent for a loaded case\n",
    "lst_mtx=[]\n",
    "lst_perf=[]\n",
    "lst_gradient=[]\n",
    "lr=2.5\n",
    "latent_dim=10\n",
    "for i in range(1000):#loop for GD interations\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(z)\n",
    "        decodedtensor=vae.decoder(z)\n",
    "        decodedtensor= layers.Reshape((1,3240))(decodedtensor)\n",
    "        y = surrogate(decodedtensor) \n",
    "        gradient = tape.gradient(y,z)\n",
    "    gr_arr=gradient.numpy().reshape(latent_dim)\n",
    "    rms=np.sqrt(np.mean(gr_arr**2))\n",
    "\n",
    "\n",
    "    lst_gradient.append(rms)\n",
    "    yarr=y.numpy()\n",
    "    yarr=yarr.reshape(1)    \n",
    "    lst_perf.append(yarr[0])\n",
    "\n",
    "              \n",
    "    decodedtensor=vae.decoder(z)\n",
    "    decodedtensor=tf.round(decodedtensor)\n",
    "    decodedarray=decodedtensor.numpy().reshape((3240))        \n",
    "    mtx=flatten_to_matrix(decodedarray,81)\n",
    "    z=z-(lr*gradient) \n",
    "    lst_mtx.append(mtx)\n",
    "\n",
    "        \n",
    "print (\"for the sample performance is:\",yarr[0],\"int:\",i)\n",
    "testmesh= Mesh_from_mtx(mtx)\n",
    "plotter = MeshPlotter(testmesh, figsize=(2, 2))\n",
    "plotter.draw_edges()\n",
    "plotter.draw_vertices(text='key', radius=0.01)\n",
    "plotter.draw_faces()\n",
    "plotter.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the Gradient Descent for the Database\n",
    "lr=2.5\n",
    "lst_z=[]\n",
    "lst_mtx=[]\n",
    "lst_perf=[]\n",
    "\n",
    "for e in range(3619): #loop for all the samples\n",
    "    test_mesh=feautures[e]\n",
    "    \n",
    "    test_mesh= test_mesh.astype('float32')\n",
    "    test_mesh=test_mesh.reshape((1,3240))\n",
    "    x= vae.encoder(test_mesh)\n",
    "    z0=x[2]\n",
    "    z=z0\n",
    "    temp_lst=[]\n",
    "    for i in range(100):#loop for GD interations\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z)\n",
    "            decodedtensor=vae.decoder(z)\n",
    "            decodedtensor= layers.Reshape((1,3240))(decodedtensor)\n",
    "            y = surrogate(decodedtensor) \n",
    "            gradient = tape.gradient(y,z)\n",
    "        yarr=y.numpy()\n",
    "        yarr=yarr.reshape(1)                \n",
    "        decodedtensor=vae.decoder(z)\n",
    "        decodedtensor=tf.round(decodedtensor)\n",
    "        decodedarray=decodedtensor.numpy().reshape((3240))        \n",
    "        mtx=flatten_to_matrix(decodedarray,81)\n",
    "        z=z-(lr*gradient) \n",
    "\n",
    "    if yarr[0]<0.26 and exist(decodedarray,feautures)==0: #if estimated performance <0.19            \n",
    "        print (z0)\n",
    "        lst_z.append(z0)\n",
    "        lst_mtx.append(mtx)\n",
    "        lst_perf.append(yarr[0])\n",
    "        print (\"for the sample:\",(e),\"for which z=\" ,z0,\"performance was:\",yarr[0])\n",
    "        testmesh= Mesh_from_mtx(mtx)\n",
    "        plotter = MeshPlotter(testmesh, figsize=(2, 2))\n",
    "        plotter.draw_edges()\n",
    "        plotter.draw_vertices(text='key', radius=0.01)\n",
    "        plotter.draw_faces()\n",
    "        plotter.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('thesiscopy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53caa4d8a770eed13d8877004b836469854a1a466533e15943c2806be1db7360"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
